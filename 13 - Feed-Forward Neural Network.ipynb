{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- MNIST\n",
    "- Dataloader, Transformation\n",
    "- Multilayer Neural Networks, Activation Function\n",
    "- Loss and Optimizer\n",
    "- Training Loop (batch training)\n",
    "- Model evaluation\n",
    "- GPU support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "\n",
    "# device config\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "\n",
    "# hyper parameters\n",
    "input_size = 784  # 28*28\n",
    "hidden_size = 500\n",
    "num_classes = 10  # 10个数字\n",
    "epoch = 2  # may increase\n",
    "batch_size = 100\n",
    "lr = 0.001\n",
    "\n",
    "\n",
    "# MNIST\n",
    "train_dataset = torchvision.datasets.MNIST(root='./data', \n",
    "                                           train=True, \n",
    "                                           transform=transforms.ToTensor(), \n",
    "                                           download=True)\n",
    "test_dataset = torchvision.datasets.MNIST(root='./data', train=False, \n",
    "                                          transform=transforms.ToTensor())\n",
    "\n",
    "\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False)   \n",
    "# test也要batch？\n",
    "\n",
    "\n",
    "examples = iter(train_loader)\n",
    "samples, labels = next(examples)\n",
    "print(samples.shape, labels.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Device configuration\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)\n",
    "# Hyper-parameters \n",
    "input_size = 784 # 28x28\n",
    "hidden_size = 500 \n",
    "num_classes = 10\n",
    "num_epochs = 2\n",
    "batch_size = 64\n",
    "learning_rate = 0.001\n",
    "\n",
    "# MNIST dataset \n",
    "train_dataset = torchvision.datasets.MNIST(root='./data', \n",
    "                                           train=True, \n",
    "                                           transform=transforms.ToTensor(),  \n",
    "                                           download=True)\n",
    "\n",
    "test_dataset = torchvision.datasets.MNIST(root='./data', \n",
    "                                          train=False, \n",
    "                                          transform=transforms.ToTensor())\n",
    "\n",
    "# Data loader\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, \n",
    "                                           batch_size=batch_size, \n",
    "                                           shuffle=True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, \n",
    "                                          batch_size=batch_size, \n",
    "                                          shuffle=False)\n",
    "\n",
    "examples = iter(test_loader)\n",
    "# example_data, example_targets = next(examples)\n",
    "samples, labels = next(examples)\n",
    "\n",
    "# batch_size, one channel(没有其他颜色)，\n",
    "print(samples.shape, labels.shape)\n",
    "# print(samples[1][0])\n",
    "\n",
    "# plot\n",
    "for i in range(6):\n",
    "    plt.subplot(2, 3, i+1)\n",
    "    plt.imshow(samples[i][0], cmap='coolwarm')  # 绘制图像的准备。 # colormap，\n",
    "    # plt.plot(samples[i][0])   # 这个只能画出“线性”的关系，而不能画出“像素”的关系\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "class NeuralNet(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_classes):\n",
    "        super().__init__()\n",
    "        self.l1 = nn.Linear(input_size, hidden_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.l2 = nn.Linear(hidden_size, num_classes)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = self.l1(x)\n",
    "        out = self.relu(out)\n",
    "        out = self.l2(out)\n",
    "        return out   # don't activation function\n",
    "    \n",
    "model = NeuralNet(input_size, hidden_size, num_classes).to(device)\n",
    "\n",
    "# loss and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "# reaining loop\n",
    "\n",
    "n_total_steps = len(train_loader)\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        # 100, 1, 28, 28\n",
    "        # -> 100, 784\n",
    "        images = images.reshape(-1, 28*28).to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        # forward\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "    \n",
    "        # backward\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "        if (i+1) % 100 == 0:\n",
    "            print(f'epoch {epoch}/{num_epochs}, step {i+1}/{n_total_steps}, loss = {loss:.4f}')\n",
    "        \n",
    "# test\n",
    "with torch.no_grad():\n",
    "    n_test_steps = len(test_loader)\n",
    "    print(n_test_steps)\n",
    "    n_correct = 0\n",
    "    n_samples = 0\n",
    "    for images, labels in test_loader:\n",
    "        images = images.reshape(-1, 28*28).to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = model(images)\n",
    "        \n",
    "        _, predictions = torch.max(outputs, 1)  # 取 index\n",
    "        n_samples += labels.shape[0]\n",
    "        n_correct += (predictions == labels).sum().item()\n",
    "    \n",
    "    acc = 100.0 * n_correct / n_samples\n",
    "    print(f'accuracy = {acc}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "class NeuralNet(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_classes):\n",
    "        super().__init__()\n",
    "        self.l1 = nn.Linear(input_size, hidden_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.l2 = nn.Linear(hidden_size, num_classes)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = self.l1(x)\n",
    "        out = self.relu(out)\n",
    "        out = self.l2(out)\n",
    "        return out   # don't activation function\n",
    "    \n",
    "model = NeuralNet(input_size, hidden_size, num_classes).to(device)\n",
    "\n",
    "# loss and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "# reaining loop\n",
    "\n",
    "n_total_steps = len(train_loader)\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        # 100, 1, 28, 28\n",
    "        # -> 100, 784\n",
    "        images = images.reshape(-1, 28*28).to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        # forward\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "    \n",
    "        # backward\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "        if (i+1) % 100 == 0:\n",
    "            print(f'epoch {epoch}/{num_epochs}, step {i+1}/{n_total_steps}, loss = {loss:.4f}')\n",
    "        \n",
    "# test\n",
    "with torch.no_grad():\n",
    "    n_test_steps = len(test_loader)\n",
    "    print(n_test_steps)\n",
    "    n_correct = 0\n",
    "    n_samples = 0\n",
    "    for i, (images, labels) in enumerate(test_loader):\n",
    "        images = images.reshape(-1, 28*28).to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = model(images)\n",
    "        \n",
    "        _, predictions = torch.max(outputs, 1)  # 取 index\n",
    "        n_samples += labels.shape[0]\n",
    "        n_correct += (predictions == labels).sum().item()\n",
    "        acc = 100.0 * n_correct / n_samples\n",
    "        if (i+1) % 10 == 0:\n",
    "            print(f'step {i+1}/{n_test_steps}, accuracy = {acc:.4f}')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# - tensorboard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "writer = SummaryWriter()\n",
    "\n",
    "# ----------------------------------------------------------------------\n",
    "# Device configuration\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)\n",
    "# Hyper-parameters \n",
    "input_size = 784 # 28x28\n",
    "hidden_size = 500 \n",
    "num_classes = 10\n",
    "num_epochs = 2\n",
    "batch_size = 64\n",
    "learning_rate = 0.001\n",
    "\n",
    "# MNIST dataset \n",
    "train_dataset = torchvision.datasets.MNIST(root='./data', \n",
    "                                           train=True, \n",
    "                                           transform=transforms.ToTensor(),  \n",
    "                                           download=True)\n",
    "\n",
    "test_dataset = torchvision.datasets.MNIST(root='./data', \n",
    "                                          train=False, \n",
    "                                          transform=transforms.ToTensor())\n",
    "\n",
    "# Data loader\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, \n",
    "                                           batch_size=batch_size, \n",
    "                                           shuffle=True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, \n",
    "                                          batch_size=batch_size, \n",
    "                                          shuffle=False)\n",
    "\n",
    "examples = iter(test_loader)\n",
    "# example_data, example_targets = next(examples)\n",
    "samples, labels = next(examples)\n",
    "\n",
    "# batch_size, one channel(没有其他颜色)，\n",
    "print(samples.shape, labels.shape)\n",
    "# print(samples[1][0])\n",
    "\n",
    "# plot\n",
    "for i in range(6):\n",
    "    plt.subplot(2, 3, i+1)\n",
    "    plt.imshow(samples[i][0], cmap='coolwarm')  # 绘制图像的准备。 # colormap，\n",
    "    # plt.plot(samples[i][0])   # 这个只能画出“线性”的关系，而不能画出“像素”的关系\n",
    "# plt.show()\n",
    "\n",
    "# tensorboard 1\n",
    "img_grid = torchvision.utils.make_grid(samples)\n",
    "writer.add_image('mnist_images', img_grid)\n",
    "writer.close()\n",
    "sys.exit()\n",
    "\n",
    "# ------------------------------------------------------------------------------\n",
    "\n",
    "class NeuralNet(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_classes):\n",
    "        super().__init__()\n",
    "        self.l1 = nn.Linear(input_size, hidden_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.l2 = nn.Linear(hidden_size, num_classes)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = self.l1(x)\n",
    "        out = self.relu(out)\n",
    "        out = self.l2(out)\n",
    "        return out   # don't activation function\n",
    "    \n",
    "model = NeuralNet(input_size, hidden_size, num_classes).to(device)\n",
    "\n",
    "# loss and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "# tensorboard 2\n",
    "writer.add_graph(model, samples.reshape(-1, 28*28).to(device))\n",
    "writer.close()\n",
    "sys.exit()\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# reaining loop\n",
    "\n",
    "n_total_steps = len(train_loader)\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        # 100, 1, 28, 28\n",
    "        # -> 100, 784\n",
    "        images = images.reshape(-1, 28*28).to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        # forward\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "    \n",
    "        # backward\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "        if (i+1) % 100 == 0:\n",
    "            print(f'epoch {epoch}/{num_epochs}, step {i+1}/{n_total_steps}, loss = {loss:.4f}')\n",
    "        \n",
    "# test\n",
    "with torch.no_grad():\n",
    "    n_test_steps = len(test_loader)\n",
    "    print(n_test_steps)\n",
    "    n_correct = 0\n",
    "    n_samples = 0\n",
    "    for i, (images, labels) in enumerate(test_loader):\n",
    "        images = images.reshape(-1, 28*28).to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = model(images)\n",
    "        \n",
    "        _, predictions = torch.max(outputs, 1)  # 取 index\n",
    "        n_samples += labels.shape[0]\n",
    "        n_correct += (predictions == labels).sum().item()\n",
    "        acc = 100.0 * n_correct / n_samples\n",
    "        if (i+1) % 10 == 0:\n",
    "            print(f'step {i+1}/{n_test_steps}, accuracy = {acc:.4f}')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "writer = SummaryWriter()\n",
    "\n",
    "# ----------------------------------------------------------------------\n",
    "# Device configuration\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)\n",
    "# Hyper-parameters \n",
    "input_size = 784 # 28x28\n",
    "hidden_size = 500 \n",
    "num_classes = 10\n",
    "num_epochs = 2\n",
    "batch_size = 64\n",
    "learning_rate = 0.001\n",
    "\n",
    "# MNIST dataset \n",
    "train_dataset = torchvision.datasets.MNIST(root='./data', \n",
    "                                           train=True, \n",
    "                                           transform=transforms.ToTensor(),  \n",
    "                                           download=True)\n",
    "\n",
    "test_dataset = torchvision.datasets.MNIST(root='./data', \n",
    "                                          train=False, \n",
    "                                          transform=transforms.ToTensor())\n",
    "\n",
    "# Data loader\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, \n",
    "                                           batch_size=batch_size, \n",
    "                                           shuffle=True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, \n",
    "                                          batch_size=batch_size, \n",
    "                                          shuffle=False)\n",
    "\n",
    "examples = iter(test_loader)\n",
    "# example_data, example_targets = next(examples)\n",
    "samples, labels = next(examples)\n",
    "\n",
    "# batch_size, one channel(没有其他颜色)，\n",
    "print(samples.shape, labels.shape)\n",
    "# print(samples[1][0])\n",
    "\n",
    "# plot\n",
    "for i in range(6):\n",
    "    plt.subplot(2, 3, i+1)\n",
    "    plt.imshow(samples[i][0], cmap='coolwarm')  # 绘制图像的准备。 # colormap，\n",
    "    # plt.plot(samples[i][0])   # 这个只能画出“线性”的关系，而不能画出“像素”的关系\n",
    "# plt.show()\n",
    "\n",
    "# tensorboard 1\n",
    "img_grid = torchvision.utils.make_grid(samples)\n",
    "writer.add_image('mnist_images', img_grid)\n",
    "writer.close()\n",
    "sys.exit()\n",
    "\n",
    "# ------------------------------------------------------------------------------\n",
    "\n",
    "class NeuralNet(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_classes):\n",
    "        super().__init__()\n",
    "        self.l1 = nn.Linear(input_size, hidden_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.l2 = nn.Linear(hidden_size, num_classes)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = self.l1(x)\n",
    "        out = self.relu(out)\n",
    "        out = self.l2(out)\n",
    "        return out   # don't activation function\n",
    "    \n",
    "model = NeuralNet(input_size, hidden_size, num_classes).to(device)\n",
    "\n",
    "# loss and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "# tensorboard 2\n",
    "writer.add_graph(model, samples.reshape(-1, 28*28).to(device))\n",
    "writer.close()\n",
    "sys.exit()\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# reaining loop\n",
    "\n",
    "n_total_steps = len(train_loader)\n",
    "\n",
    "running_loss = 0.0\n",
    "running_correct = 0.1\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        # 100, 1, 28, 28\n",
    "        # -> 100, 784\n",
    "        images = images.reshape(-1, 28*28).to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        # forward\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "    \n",
    "        # backward\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # loss values and accuracy \n",
    "        running_loss += loss.item()\n",
    "        _, predictions = torch.max(outputs, 1)\n",
    "        running_correct += (predictions == labels).sum().item()\n",
    "        \n",
    "        if (i+1) % 100 == 0:\n",
    "            print(f'epoch {epoch}/{num_epochs}, step {i+1}/{n_total_steps}, loss = {loss:.4f}')\n",
    "            writer.add_scalar('training loss', running_loss / 100, epoch * n_total_steps + i)\n",
    "            writer.add_scalar('accuracy', running_correct / 100, epoch * n_total_steps + i)\n",
    "            running_loss = 0.0\n",
    "            running_correct = 0.0\n",
    "# test\n",
    "with torch.no_grad():\n",
    "    n_test_steps = len(test_loader)\n",
    "    print(n_test_steps)\n",
    "    n_correct = 0\n",
    "    n_samples = 0\n",
    "    for i, (images, labels) in enumerate(test_loader):\n",
    "        images = images.reshape(-1, 28*28).to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = model(images)\n",
    "        \n",
    "        _, predictions = torch.max(outputs, 1)  # 取 index\n",
    "        n_samples += labels.shape[0]\n",
    "        n_correct += (predictions == labels).sum().item()\n",
    "        acc = 100.0 * n_correct / n_samples\n",
    "        if (i+1) % 10 == 0:\n",
    "            print(f'step {i+1}/{n_test_steps}, accuracy = {acc:.4f}')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- tensorboard 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "writer = SummaryWriter()\n",
    "\n",
    "# ----------------------------------------------------------------------\n",
    "# Device configuration\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)\n",
    "# Hyper-parameters \n",
    "input_size = 784 # 28x28\n",
    "hidden_size = 500 \n",
    "num_classes = 10\n",
    "num_epochs = 2\n",
    "batch_size = 64\n",
    "learning_rate = 0.001\n",
    "\n",
    "# MNIST dataset \n",
    "train_dataset = torchvision.datasets.MNIST(root='./data', \n",
    "                                           train=True, \n",
    "                                           transform=transforms.ToTensor(),  \n",
    "                                           download=True)\n",
    "\n",
    "test_dataset = torchvision.datasets.MNIST(root='./data', \n",
    "                                          train=False, \n",
    "                                          transform=transforms.ToTensor())\n",
    "\n",
    "# Data loader\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, \n",
    "                                           batch_size=batch_size, \n",
    "                                           shuffle=True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, \n",
    "                                          batch_size=batch_size, \n",
    "                                          shuffle=False)\n",
    "\n",
    "examples = iter(test_loader)\n",
    "# example_data, example_targets = next(examples)\n",
    "samples, labels = next(examples)\n",
    "\n",
    "# batch_size, one channel(没有其他颜色)，\n",
    "print(samples.shape, labels.shape)\n",
    "# print(samples[1][0])\n",
    "\n",
    "# plot\n",
    "for i in range(6):\n",
    "    plt.subplot(2, 3, i+1)\n",
    "    plt.imshow(samples[i][0], cmap='coolwarm')  # 绘制图像的准备。 # colormap，\n",
    "    # plt.plot(samples[i][0])   # 这个只能画出“线性”的关系，而不能画出“像素”的关系\n",
    "# plt.show()\n",
    "\n",
    "# tensorboard 1\n",
    "img_grid = torchvision.utils.make_grid(samples)\n",
    "writer.add_image('mnist_images', img_grid)\n",
    "writer.close()\n",
    "# sys.exit()\n",
    "\n",
    "# ------------------------------------------------------------------------------\n",
    "\n",
    "class NeuralNet(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_classes):\n",
    "        super().__init__()\n",
    "        self.l1 = nn.Linear(input_size, hidden_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.l2 = nn.Linear(hidden_size, num_classes)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = self.l1(x)\n",
    "        out = self.relu(out)\n",
    "        out = self.l2(out)\n",
    "        return out   # don't activation function\n",
    "    \n",
    "model = NeuralNet(input_size, hidden_size, num_classes).to(device)\n",
    "\n",
    "# loss and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "# tensorboard 2\n",
    "writer.add_graph(model, samples.reshape(-1, 28*28).to(device))\n",
    "writer.close()\n",
    "sys.exit()\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# reaining loop\n",
    "\n",
    "n_total_steps = len(train_loader)\n",
    "\n",
    "running_loss = 0.0\n",
    "running_correct = 0.1\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        # 100, 1, 28, 28\n",
    "        # -> 100, 784\n",
    "        images = images.reshape(-1, 28*28).to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        # forward\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "    \n",
    "        # backward\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # loss values and accuracy \n",
    "        running_loss += loss.item()\n",
    "        _, predictions = torch.max(outputs, 1)\n",
    "        running_correct += (predictions == labels).sum().item()\n",
    "        \n",
    "        if (i+1) % 100 == 0:\n",
    "            print(f'epoch {epoch}/{num_epochs}, step {i+1}/{n_total_steps}, loss = {loss:.4f}')\n",
    "            writer.add_scalar('training loss', running_loss / 100, epoch * n_total_steps + i)\n",
    "            writer.add_scalar('accuracy', running_correct / 100, epoch * n_total_steps + i)\n",
    "            running_loss = 0.0\n",
    "            running_correct = 0.0\n",
    "# test\n",
    "with torch.no_grad():\n",
    "    n_test_steps = len(test_loader)\n",
    "    print(n_test_steps)\n",
    "    n_correct = 0\n",
    "    n_samples = 0\n",
    "    for i, (images, labels) in enumerate(test_loader):\n",
    "        images = images.reshape(-1, 28*28).to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = model(images)\n",
    "        \n",
    "        _, predictions = torch.max(outputs, 1)  # 取 index\n",
    "        n_samples += labels.shape[0]\n",
    "        n_correct += (predictions == labels).sum().item()\n",
    "        acc = 100.0 * n_correct / n_samples\n",
    "        if (i+1) % 10 == 0:\n",
    "            print(f'step {i+1}/{n_test_steps}, accuracy = {acc:.4f}')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- tensorboard 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n",
      "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "938\n",
      "epoch 1/1, step 100/938, loss = 0.3268\n",
      "epoch 1/1, step 200/938, loss = 0.1863\n",
      "epoch 1/1, step 300/938, loss = 0.1936\n",
      "epoch 1/1, step 400/938, loss = 0.2932\n",
      "epoch 1/1, step 500/938, loss = 0.2295\n",
      "epoch 1/1, step 600/938, loss = 0.0685\n",
      "epoch 1/1, step 700/938, loss = 0.2538\n",
      "epoch 1/1, step 800/938, loss = 0.2269\n",
      "epoch 1/1, step 900/938, loss = 0.1619\n",
      "157\n",
      "step 10/157, accuracy = 96.7188\n",
      "step 20/157, accuracy = 95.5469\n",
      "step 30/157, accuracy = 95.3646\n",
      "step 40/157, accuracy = 94.8438\n",
      "step 50/157, accuracy = 95.2188\n",
      "step 60/157, accuracy = 95.2604\n",
      "step 70/157, accuracy = 95.1116\n",
      "step 80/157, accuracy = 95.2148\n",
      "step 90/157, accuracy = 95.5556\n",
      "step 100/157, accuracy = 95.6094\n",
      "step 110/157, accuracy = 95.7528\n",
      "step 120/157, accuracy = 95.9896\n",
      "step 130/157, accuracy = 96.1298\n",
      "step 140/157, accuracy = 96.2723\n",
      "step 150/157, accuracy = 96.3854\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 6 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "writer = SummaryWriter('runs/mnist1')\n",
    "\n",
    "# ----------------------------------------------------------------------\n",
    "# Device configuration\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)\n",
    "# Hyper-parameters \n",
    "input_size = 784 # 28x28\n",
    "hidden_size = 500 \n",
    "num_classes = 10\n",
    "num_epochs = 1\n",
    "batch_size = 64\n",
    "lr = 0.001\n",
    "\n",
    "# MNIST dataset \n",
    "train_dataset = torchvision.datasets.MNIST(root='./data', \n",
    "                                           train=True, \n",
    "                                           transform=transforms.ToTensor(),  \n",
    "                                           download=True)\n",
    "\n",
    "test_dataset = torchvision.datasets.MNIST(root='./data', \n",
    "                                          train=False, \n",
    "                                          transform=transforms.ToTensor())\n",
    "\n",
    "# Data loader\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, \n",
    "                                           batch_size=batch_size, \n",
    "                                           shuffle=True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, \n",
    "                                          batch_size=batch_size, \n",
    "                                          shuffle=False)\n",
    "\n",
    "examples = iter(test_loader)\n",
    "# example_data, example_targets = next(examples)\n",
    "samples, labels = next(examples)\n",
    "\n",
    "# batch_size, one channel(没有其他颜色)，\n",
    "print(samples.shape, labels.shape)\n",
    "# print(samples[1][0])\n",
    "\n",
    "# plot\n",
    "for i in range(6):\n",
    "    plt.subplot(2, 3, i+1)\n",
    "    plt.imshow(samples[i][0], cmap='coolwarm')  # 绘制图像的准备。 # colormap，\n",
    "    # plt.plot(samples[i][0])   # 这个只能画出“线性”的关系，而不能画出“像素”的关系\n",
    "# plt.show()\n",
    "\n",
    "# tensorboard 1\n",
    "img_grid = torchvision.utils.make_grid(samples)\n",
    "writer.add_image('mnist_images', img_grid)\n",
    "writer.close()\n",
    "# sys.exit()\n",
    "\n",
    "# ------------------------------------------------------------------------------\n",
    "\n",
    "class NeuralNet(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_classes):\n",
    "        super().__init__()\n",
    "        self.l1 = nn.Linear(input_size, hidden_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.l2 = nn.Linear(hidden_size, num_classes)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = self.l1(x)\n",
    "        out = self.relu(out)\n",
    "        out = self.l2(out)\n",
    "        return out   # don't activation function\n",
    "    \n",
    "model = NeuralNet(input_size, hidden_size, num_classes).to(device)\n",
    "\n",
    "# loss and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "# tensorboard 2\n",
    "writer.add_graph(model, samples.reshape(-1, 28*28).to(device))\n",
    "writer.close()\n",
    "# sys.exit()\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# reaining loop\n",
    "\n",
    "n_total_steps = len(train_loader)\n",
    "print(n_total_steps)\n",
    "\n",
    "running_loss = 0.0\n",
    "running_correct = 0\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        # 100, 1, 28, 28\n",
    "        # -> 100, 784\n",
    "        images = images.reshape(-1, 28*28).to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        # forward\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "    \n",
    "        # backward\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # loss values and accuracy \n",
    "        running_loss += loss.item()\n",
    "        _, predictions = torch.max(outputs, 1)\n",
    "        running_correct += (predictions == labels).sum().item()\n",
    "        \n",
    "        if (i+1) % 100 == 0:\n",
    "            print(f'epoch {epoch+1}/{num_epochs}, step {i+1}/{n_total_steps}, loss = {loss:.4f}')\n",
    "            writer.add_scalar('training loss', running_loss / 100, epoch * n_total_steps + i)\n",
    "            writer.add_scalar('accuracy', running_correct / 100, epoch * n_total_steps + i)\n",
    "            running_loss = 0.0\n",
    "            running_correct = 0\n",
    "# test\n",
    "with torch.no_grad():\n",
    "    n_test_steps = len(test_loader)\n",
    "    print(n_test_steps)\n",
    "    n_correct = 0\n",
    "    n_samples = 0\n",
    "    for i, (images, labels) in enumerate(test_loader):\n",
    "        images = images.reshape(-1, 28*28).to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = model(images)\n",
    "        \n",
    "        _, predictions = torch.max(outputs, 1)  # 取 index\n",
    "        n_samples += labels.shape[0]\n",
    "        n_correct += (predictions == labels).sum().item()\n",
    "        acc = 100.0 * n_correct / n_samples\n",
    "        if (i+1) % 10 == 0:\n",
    "            print(f'step {i+1}/{n_test_steps}, accuracy = {acc:.4f}')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir runs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
