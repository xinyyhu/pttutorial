{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这将是一个对比实现算法的过程\n",
    "\n",
    "1、manually,用numpy手动实现：预测、梯度计算、loss、参数更新\n",
    "\n",
    "2、auto gradient\n",
    "\n",
    "3、用pytorch实现loss和optimizer\n",
    "\n",
    "4、全部用pytorch实现"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# part 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# only weight not bias\n",
    "# f = w * x\n",
    "\n",
    "#target function\n",
    "# f = 2 * x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction before trainingL f(5) = 0.000\n",
      "epoch 1: w = 1.2000, dw = -120.0000, loss = 30.00000000\n",
      "epoch 2: w = 1.6800, dw = -48.0000, loss = 4.79999924\n",
      "epoch 3: w = 1.8720, dw = -19.2000, loss = 0.76800019\n",
      "epoch 4: w = 1.9488, dw = -7.6800, loss = 0.12288000\n",
      "epoch 5: w = 1.9795, dw = -3.0720, loss = 0.01966083\n",
      "epoch 6: w = 1.9918, dw = -1.2288, loss = 0.00314570\n",
      "epoch 7: w = 1.9967, dw = -0.4915, loss = 0.00050332\n",
      "epoch 8: w = 1.9987, dw = -0.1966, loss = 0.00008053\n",
      "epoch 9: w = 1.9995, dw = -0.0786, loss = 0.00001288\n",
      "epoch 10: w = 1.9998, dw = -0.0315, loss = 0.00000206\n",
      "Prediction after trainingL f(5) = 9.9990\n"
     ]
    }
   ],
   "source": [
    "x = np.array([1,2,3,4], dtype=np.float32)\n",
    "y = np.array([2,4,6,8], dtype=np.float32)\n",
    "\n",
    "w = 0.0   # for beginning\n",
    "\n",
    "# model prediction\n",
    "def forward(x):\n",
    "    return w * x\n",
    "\n",
    "# loss function = MSE\n",
    "def loss(y, y_hat):\n",
    "    return np.mean((y_hat - y)**2)\n",
    "    # return ((y_hat - y)**2).mean()\n",
    "\n",
    "# gradient\n",
    "# MSE = 1/N * (w*x - y)**2\n",
    "# MSE导数 dJ/dw = 1/N * 2x * (w*x - y)\n",
    "def  gradient(x, y, y_hat):\n",
    "    #这段视频中的代码其实是错误的，它并没有平均，dot算出来是标量，但它收敛更快，因为更新步长大了，相当于4倍于lr\n",
    "    return np.dot(2*x, y_hat-y).mean()   \n",
    "\n",
    "print(f'Prediction before trainingL f(5) = {forward(5):.3f}')\n",
    "\n",
    "\n",
    "# Training\n",
    "lr = 0.01\n",
    "n_iters = 10\n",
    "\n",
    "for epoch in range(n_iters):\n",
    "    #prediction = forward pass\n",
    "    y_pred = forward(x)\n",
    "    \n",
    "    # loss\n",
    "    l = loss(y, y_pred)\n",
    "    \n",
    "    # gradient\n",
    "    dw = gradient(x, y, y_pred)\n",
    "    \n",
    "    # update weights\n",
    "    w -= lr * dw\n",
    "    \n",
    "    if epoch % 1 == 0:\n",
    "        print(f'epoch {epoch+1}: w = {w:.4f}, dw = {dw:.4f}, loss = {l:.8f}')\n",
    "    \n",
    "print(f'Prediction after trainingL f(5) = {forward(5):.4f}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction before trainingL f(5) = 0.000\n",
      "epoch 1: w = 0.3000, dw = -30.0000, loss = 30.00000000\n",
      "epoch 2: w = 0.5550, dw = -25.5000, loss = 21.67499924\n",
      "epoch 3: w = 0.7717, dw = -21.6750, loss = 15.66018677\n",
      "epoch 4: w = 0.9560, dw = -18.4238, loss = 11.31448555\n",
      "epoch 5: w = 1.1126, dw = -15.6602, loss = 8.17471600\n",
      "epoch 6: w = 1.2457, dw = -13.3112, loss = 5.90623236\n",
      "epoch 7: w = 1.3588, dw = -11.3145, loss = 4.26725292\n",
      "epoch 8: w = 1.4550, dw = -9.6173, loss = 3.08308983\n",
      "epoch 9: w = 1.5368, dw = -8.1747, loss = 2.22753215\n",
      "epoch 10: w = 1.6063, dw = -6.9485, loss = 1.60939264\n",
      "Prediction after trainingL f(5) = 8.0313\n"
     ]
    }
   ],
   "source": [
    "x = np.array([1,2,3,4], dtype=np.float32)\n",
    "y = np.array([2,4,6,8], dtype=np.float32)\n",
    "\n",
    "w = 0.0   # for beginning\n",
    "\n",
    "# model prediction\n",
    "def forward(x):\n",
    "    return w * x\n",
    "\n",
    "# loss function = MSE\n",
    "def loss(y, y_hat):\n",
    "    return np.mean((y_hat - y)**2)\n",
    "    # return ((y_hat - y)**2).mean()\n",
    "\n",
    "# gradient\n",
    "# MSE = 1/N * (w*x - y)**2\n",
    "# MSE导数 dJ/dw = 1/N * 2x * (w*x - y)\n",
    "def  gradient(x, y, y_hat):\n",
    "    return np.mean((2*x) * (y_hat-y))\n",
    "\n",
    "print(f'Prediction before trainingL f(5) = {forward(5):.3f}')\n",
    "\n",
    "\n",
    "# Training\n",
    "lr = 0.01\n",
    "n_iters = 10\n",
    "\n",
    "for epoch in range(n_iters):\n",
    "    #prediction = forward pass\n",
    "    y_pred = forward(x)\n",
    "    \n",
    "    # loss\n",
    "    l = loss(y, y_pred)\n",
    "    \n",
    "    # gradient\n",
    "    dw = gradient(x, y, y_pred)\n",
    "    \n",
    "    # update weights\n",
    "    w -= lr * dw\n",
    "    \n",
    "    if epoch % 1 == 0:\n",
    "        print(f'epoch {epoch+1}: w = {w:.4f}, dw = {dw:.4f}, loss = {l:.8f}')\n",
    "    \n",
    "print(f'Prediction after trainingL f(5) = {forward(5):.4f}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-120.0, -30.0)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.array([1,2,3,4], dtype=np.float32)\n",
    "y = np.array([2,4,6,8], dtype=np.float32)\n",
    "y_hat = np.zeros(4, dtype=np.float32)\n",
    "\n",
    "a = np.dot(2*x, y_hat-y).mean()\n",
    "b = np.mean((2*x) * (y_hat-y))\n",
    "a,b\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# part 2 \n",
    "\n",
    "gradient with pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction before trainingL f(5) = 0.000\n",
      "epoch 1: w = 0.3000, loss = 30.00000000\n",
      "epoch 11: w = 1.6653, loss = 1.16278565\n",
      "epoch 21: w = 1.9341, loss = 0.04506890\n",
      "epoch 31: w = 1.9870, loss = 0.00174685\n",
      "epoch 41: w = 1.9974, loss = 0.00006770\n",
      "epoch 51: w = 1.9995, loss = 0.00000262\n",
      "epoch 61: w = 1.9999, loss = 0.00000010\n",
      "epoch 71: w = 2.0000, loss = 0.00000000\n",
      "epoch 81: w = 2.0000, loss = 0.00000000\n",
      "epoch 91: w = 2.0000, loss = 0.00000000\n",
      "Prediction after trainingL f(5) = 10.0000\n"
     ]
    }
   ],
   "source": [
    "# 和上面numpy采用正确gradient的方法收敛性一样\n",
    "\n",
    "x = torch.tensor([1,2,3,4], dtype=torch.float32)\n",
    "y = torch.tensor([2,4,6,8], dtype=torch.float32)\n",
    "\n",
    "w = torch.tensor(0.0, dtype=torch.float32, requires_grad=True)   # for beginning\n",
    "\n",
    "# model prediction\n",
    "def forward(x):\n",
    "    return w * x\n",
    "\n",
    "# loss function = MSE\n",
    "def loss(y, y_hat):\n",
    "    return torch.mean((y_hat - y)**2)\n",
    "    # return ((y_hat - y)**2).mean()\n",
    "\n",
    "# gradient\n",
    "# 用pytorch的，不再需要单独定义\n",
    "\n",
    "print(f'Prediction before trainingL f(5) = {forward(5):.3f}')\n",
    "\n",
    "\n",
    "# Training\n",
    "lr = 0.01\n",
    "n_iters = 100\n",
    "\n",
    "for epoch in range(n_iters):\n",
    "    #prediction = forward pass\n",
    "    y_pred = forward(x)\n",
    "    \n",
    "    # loss\n",
    "    l = loss(y, y_pred)\n",
    "    \n",
    "    # gradient = backward pass\n",
    "    l.backward()\n",
    "    \n",
    "    # update weights\n",
    "    with torch.no_grad():\n",
    "        w -= lr * w.grad\n",
    "    \n",
    "    # 梯度清零\n",
    "    w.grad.zero_()\n",
    "    \n",
    "    if epoch % 10 == 0:\n",
    "        print(f'epoch {epoch+1}: w = {w:.4f}, loss = {l:.8f}')\n",
    "    \n",
    "print(f'Prediction after trainingL f(5) = {forward(5):.4f}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
